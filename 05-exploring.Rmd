# Exploring the Run Time for All Male Runners {#exploring}

Now that we have completed the extraction of our data from the tables published on the Cherry Blossom Web site, we can begin to study the relationship between age and run time. Typically, we first examine our data graphically in a scatter plot with run time on the y-axis and age on the x-axis. We can make such a scatter plot for the male runners with the following call to `ggplot()`.

```{r scatterplot-default, fig.cap="Default Scatter Plot for Run Time vs. Age for Male Runners. This plot demonstrates that a simple scatter plot of run time by age for the 70,000 male runners leads to such severe over plotting that the shape of the data is not discernible."}
ggplot(men_df, aes(age, time)) +
  geom_point()
```

The resulting plot appears in Figure \@ref(fig:scatterplot-default). Most of the points appear as a black blob in the scatter plot because so many points have been plotted on top of each other. The shape of the distribution is obscured because we cannot see which regions of the (age, run time) space are more densely populated. Notice also the vertical stripes in the plot. These are the result of runner’s age being reported to the nearest year, which results in more over plotting. In the next section, we consider a few alterations to this default scatter plot that address the problem of over plotting.

## Making Plots with Many Observations

There are several modifications we can make to the plot in Figure \@ref(fig:scatterplot-default) to ameliorate the effect of over plotting. We can reduce the size of the plotting symbol, use transparent colors for the plotting symbol, and add a small amount of random noise to the age variable. Alternatively, we can create a plot that reveals a smoothed version of the density of the points in each region. We can also make a series of boxplots instead of a scatter plot. We demonstrate each of these approaches in this section.

```{r scatterplot-fixed, fig.cap="Revised Scatter Plot of Male Runners. This plot revises the simple scatter plot by changing the plotting symbol from a circle to a point, reducing the size of the plotting symbol, using a transparent color for the points, and adding a small amount of random noise to age. Now we see the shape of the high density region containing most of the runners and the slight upward trend of time with increasing age."}
men_df %>% 
  filter(age > 5) %>% 
  ggplot(aes(age, time)) +
  geom_jitter(shape = '.', size = 2, alpha = 0.2, height = 0, width = 0.5, color = '#54278f')
```

Our first plot appears in Figure \@ref(fig:scatterplot-fixed). This plot is much improved from the initial one in Figure \@ref(fig:scatterplot-default). We can see where the bulk of the runners are, including what appears to be a slight upward curvature in run time as age increases and a skew distribution of run time given age. We can also see the small group of runners with very fast run times.

```{r scatterplot-smooth, fig.cap="Smoothed Scatter Plot of Male Runners Race Times vs. Age. This plot offers an alternative to the scatter plot that uses jittering and transparent color to ameliorate the over plotting. Here there is no need to jitter age because the smoothing action essentially does that for us by spreading an individual runner’s (age, run time) pair over a small region. The shape of the high density region has a very similar shape to the earlier plot."}
men_df %>% 
  filter(age > 5) %>% 
  ggplot(aes(age, time)) +
  stat_density_2d(aes(fill = ..density..), geom = 'raster', contour = FALSE) +
  scale_fill_gradientn(colors = c('white', 'dodgerblue3', 'dodgerblue4'), values = c(0, 0.5, 1))
```

The smoothed two-dimensional density plot in Figure \@ref(fig:scatterplot-smooth) shows a very similar shape to our plot in Figure \@ref(fig:scatterplot-fixed).

A very different approach to these scatter plots is to graphically display summary statistics of run time for subgroups of runners with roughly the same age. Here, we group the runners into 10-year age intervals and plot the summaries for each subgroup in the form of a boxplot (see Figure \@ref(fig:boxplots-age)). With these side-by-side boxplots, the size of the data does not obscure the main features, e.g., the quartiles and tails for an age group. To make these boxplots, we categorize age using the `cut()` function. We first remove those runners under 15 or who have unrealistic run times. Then we categorize age with

```{r}
men_df_agecat <- men_df %>% 
  filter(time > 30, !is.na(age), age > 15) %>% 
  mutate(age_cat = cut(age, breaks = c(seq(15, 75, 10), 90)))

table(men_df_agecat$age_cat)
```

This new variable, `age_cat`, is a factor that categorizes age into 10-year intervals with the exception of all of those over 75 being lumped together into one interval.

We see in Figure \@ref(fig:boxplots-age) that we have created a series of boxplots rather than a scatter plot. We observe in this plot that the upper quartile increases faster with age than the median and lower quartile. In the next section, we try summarizing this relationship between age and run time more formally.

```{r boxplots-age, fig.cap="Side-by-Side Boxplots of Male Runners’ Run Time vs. Age. This sequence of boxplots shows the quartiles of time for men grouped into 10-year age intervals. As age increases, all the quartiles increase. However, the box becomes asymmetrical with age, which indicates that the upper quartile increases faster than the median and lower quartile."}
men_df_agecat %>% 
  ggplot(aes(age_cat, time)) +
  geom_boxplot() +
  labs(x = 'Age (years)', y = 'Run time (minutes)')
```

## Fitting Models to Average Performance

As seen in Figure \@ref(fig:boxplots-age), the average performance seems to curve upward with age. A simple linear model may be inadequate to describe this relationship. To see how well the simple linear model captures the relationship (or not) between run time and age, we fit the model with

```{r}
lm_age <- lm(time ~ age, data = men_df_agecat)
```

The `lm()` function performs least squares to find the best fitting line to our data, which we see has the following intercept and slope:

```{r}
lm_age$coefficients
```

We have assigned the return value from `lm()` to `lm_age`. This object contains the coefficients from the fit, predicted values, residuals, and other information about the linear least squares fit of run time to age. We can retrieve a brief summary of the fit with a call to `summary()` as follows:

```{r}
summary(lm_age)
```

To help us assess how well the simple linear model fits the data we plot the residuals against age. As with the original scatter plot of run time against age, we need to address the issue of over plotting. Further, to help us see any curvature in the residuals, we add to the plot a horizontal line at 0. We do this with

```{r}
p <- men_df_agecat %>% 
  modelr::add_residuals(lm_age) %>% 
  ggplot(aes(age, resid)) +
  stat_density_2d(aes(fill = ..density..), geom = 'raster', contour = FALSE) +
  scale_fill_gradientn(colors = c('white', 'dodgerblue3', 'dodgerblue4'), values = c(0, 0.5, 1)) +
  geom_hline(yintercept = 0, color = 'navy')
```

To help us further discern any pattern in the residuals, we augment this residual plot with a smooth curve of local averages of the residuals from the fit. That is, for a particular age, say 37, we take a weighted average of the residuals for those runners with an age in a small neighborhood of 37. Such a locally fitted curve allows us to better see deviations in the pattern of residuals.

```{r residuals-lm, fig.cap="Residual Plot from Fitting a Simple Linear Model of Performance to Age. Shown here is a smoothed scatter plot of the residuals from the fit of the simple linear model of run time to age for male runners who are 15 to 80 years old. Overlaid on the scatter plot are two curves. The “curve” in dark blue is a solid horizontal line at $y = 0$. The red dashed curve is a local smooth of the residuals."}
p + geom_smooth(se = FALSE, linetype = 'dashed', color = 'firebrick')
```

The augmented smoothed scatter plot appears in Figure \@ref(fig:residuals-lm). We see that the simple linear model tends to underestimate the run time for men over 60. This confirms our observations from the boxplot and smooth scatter plot of the nonlinear trend in run time. The simple linear model is not able to capture the change in performance with age.

We consider two approaches to a more complex fit: a piecewise linear model and a nonparametric smooth curve. For the latter, we simply take local weighted averages of time as age varies, just as we smoothed the residuals from the linear fit. We use `loess()` to do this with

```{r}
men_res_lo <- loess(time ~ age, data = men_df_agecat)
```

and we make predictions for all ages ranging from 20 to 80 with

```{r}
age20to80 <- 20:80
men_res_lo_pr <- predict(men_res_lo, data.frame(age = age20to80))
```

The curve appears in Figure \@ref(fig:piecewise-fits).

Next we fit a piecewise linear model, which consists of several connected line segments.
This is similar to the idea of the locally smoothed curve from `loess()` in that it allows us to
bend the line at certain points to better fit the data. The difference is that the fit must be
linear between the hinges. We place hinges at 30, 40, 50, and 60 and thus allow the slope
of the line to change at these decade markers. The fitted “curve” appears in Figure \@ref(fig:piecewise-fits).

How do we fit such a model to our data? Before we fit the full piecewise model, we
consider a simpler model with one hinge at 50. We first create an `over50` variable that takes on the value 0 for ages 50 and under and otherwise holds the number of years over 50, e.g. 1 for someone who is 51, 2 for someone who is 52, and so on. If our fit is $a + b \times \textrm{age} + c \times \textrm{over50}$ then for an age below 50 this is simply $a + b \times \textrm{age}$ and for an age over 50 it is equivalent to $(a - 50c) + (b + c) \textrm{age}$. We see that the coefficient $c$ is the change in the slope from below 50 to above 50, and the intercept makes the line segments connect.

Our first task then is to create this over50 variable. We use the `pmax()` function, which
performs an element-wise or “parallel” maximum. We find the maximum of each element
of `men_df$age - 50` and 0 with

```{r}
over50 <- pmax(0, men_df_agecat$age - 50)
```

We then fit this augmented model as follows.

```{r}
lm_over50 <- lm(time ~ age + over50, data = men_df_agecat)
summary(lm_over50)
```

Now the slope of the line for those under 50 is less steep than in our original simple linear model, and for ages over 50, the model indicates the average man slows by 0.67 minutes, which is an additional 0.56 minutes a year compared to those under fifty.

We can create the `over30`, `over40`, etc. variables as follows:

```{r}
decades <- seq(30, 60, by = 10)
over_age <- map_dfc(decades, function(x) {
  name <- paste0('over', x)
  df <- data_frame(pmax(0, men_df_agecat$age - x))
  names(df) <- name
  df
})
tail(over_age)
```

Now that we have each of these variables, we can create the model.

```{r}
lm_piecewise <- men_df_agecat %>% 
  bind_cols(over_age) %>% 
  select(time, age, starts_with('over')) %>% 
  lm(time ~ ., data = .)
summary(lm_piecewise)
```

This model has an interpretation similar to the model with just `age` and `over50`. That is, the coefficient for, say, `over40` is the change in the slope for ages in (30, 40] to ages in (40, 50].

Notice that the coefficient for `over60` is essentially 0, meaning that those over 60 do not slow down any faster than those in their fifties, i.e. about 0.494 minutes more per year for each year over 50 for a total of about 0.66 minutes for the 10-mile race per year.

How do we plot this piecewise linear function that we have fitted? As with the loess curve,
we can use `predict()` to provide fitted values for each age value from 20 to 80. However, we
need to provide `predict()` with all of the covariates used in making the fit, i.e., `age`, `over30`, `over40`, `over50`, and `over60`. We can create a data frame of these covariates just as we did for the full data set as follows:

```{r}
over_age_df <- map_dfc(decades, function(x) {
  name <- paste0('over', x)
  df <- data_frame(pmax(0, age20to80 - x))
  names(df) <- name
  df
}) %>% 
  bind_cols(age = age20to80, .)
tail(over_age_df)
```

Then we call `predict()` passing it the `lm` object, i.e. `lm_piecewise`, with the details of the fit and also the covariates to use to make the predictions, i.e. `over_age_df`. That is, we call `predict()` with

```{r}
over_age_df <- over_age_df %>% modelr::add_predictions(lm_piecewise)
```

We plot this fitted piecewise linear function and the `loess` curve with

```{r piecewise-fits, warning=F, fig.cap="Piecewise Linear and Loess Curves Fitted to Run Time vs. Age. Here we have plotted the fitted curves from `loess()` and a piecewise linear model with hinges at 30, 40, 50, and 60. These curves follow each other quite closely. However, there appears to be more curvature in the over 50 loess fit that is not captured in the piecewise linear fit."}
over_age_df %>% 
  mutate(loess = men_res_lo_pr) %>% 
  gather(type, value, pred, loess) %>% 
ggplot(aes(age, value, color = type)) +
  geom_line() +
  scale_color_few(name = '', labels = c('loess', 'piecewise')) +
  labs(title = 'Predicted race times', x = 'Age (years)', y = 'Time (minutes)')
```

The two fitted curves appear in Figure \@ref(fig:piecewise-fits). We see that they follow each other quite closely. The main deviation is in the over 70 group. We did not include a hinge at 70 so our fitted model is unable to capture the sharper increase for those over 70. We may want to consider adding this additional hinge to our model to see if it improves the fit. It may seem that we have made great progress in modeling the average performance, but we must interpret these results with care. For example, suppose, as seems likely, that younger runners who are slow tend to drop out of racing as they age so older runners who do participate are those who tend to be faster. This can bias our estimate of how running speed changes with age. Additionally, these data consist of 14 cross-sectional snapshots of runners. We might ask ourselves whether or not the composition of the participants has changed over this time period. These concerns are the topics of the next two sections.

## Cross-Sectional Data and Covariates

In our earlier analysis, we examined the average performance for runners of different ages. That is, we looked at average performance for, e.g., 30-39 year olds and 40-49 year olds in the Cherry Blossom road race. However, we have not seen how a runner’s performance changes as he or she ages. These two groups (30-39 and 40-49 year olds) are composed of different people and if these groups of people differ from each other in some significant ways, e.g., those in their 30s are more likely to be world class runners and those in their 40s are more likely to be local amateur athletes, then we might be misled by comparing these two group’s average performances. To further complicate the matter, we have data from 14 different races so we are also averaging across the participants in these different races. We expect the average performances to be the same across the years. However, each year we have a self-selected group of participants, and we might wonder whether the composition of the participants has changed over the years. If it has, that could further complicate inference.

We know that the Cherry Blossom 10-mile run has been increasingly popular. Figure \@ref(fig:runner-count) indicates that the number of male runners has more than doubled over the 14 years. It seems reasonable to question if the demographics of the participants have changed over this time period.

```{r runner-count, fig.cap="Line Plot of the Number of Male Runners by Year. This plot shows that the number of male runners in the Cherry Blossom 10-mile race has more than doubled from 1999 to 2012."}
men_df_agecat %>%
  ggplot(aes(factor(year))) +
  geom_bar(width = 0.6) +
  labs(x = 'Year', y = 'Number of Runners')
```

Historically, the race was used as a preparation for the Boston Marathon. The fastest runners in the Cherry Blossom primarily come from Ethiopia, Kenya, and Tanzania. And, their times are within a minute or two of the world record of 44:24 set in 2005 by Haile Gebrselassie from Ethiopia, who was 32 at the time (see http://inglog.com/tools/world-records/). Professional runners continue to compete in the Cherry Blossom road race.

Let’s compare the distribution of performance for the earliest and latest years, i.e., the
1999 and 2012 races. We see below that while the fastest man has gotten faster from 1999 to 2012, the quartiles of the 2012 distribution are each about 3 minutes slower compared to 1999:

```{r}
men_df_agecat %>% 
  filter(year == 1999) %>% 
  select(time) %>% 
  summary()
```

```{r}
men_df_agecat %>% 
  filter(year == 2012) %>% 
  select(time) %>% 
  summary()
```

Could it be that the men competing in 2012 are older and therefore slower than their counterparts in 1999? We can compare the age distributions of the runners in the two races.

```{r density-twoyears, fig.cap="Density Curves for the Age of Male Runners in 1999 and 2012. These two density curves have quite different shapes. The 1999 male runners have a broad, nearly flat mode where they are roughly evenly distributed in age from 28 to 45. In contrast, the 2012 runners are younger with a sharper peak just under 30 years and a skew right distribution."}
men_df_agecat %>% 
  filter(year %in% c(1999, 2012)) %>% 
  ggplot(aes(age, color = factor(year))) +
  geom_line(stat = 'density') +
  scale_color_few(name = 'Year') +
  labs(x = 'Age', y = 'Density')
```

The density curves in Figure \@ref(fig:density-twoyears) are surprising. The males in 2012 are not older. In fact, the opposite is the case. There are many more younger men in 2012 in comparison to 1999, as evidenced by the sharp peak in the 2012 distribution at about 30. We can also compare these two distributions with a quantile-quantile plot (see Figure \@ref(fig:age-qq)). The difference in performance between 1999 and 2012 is more subtle than having an aging population of runners. We need to control the covariates, age and year, simultaneously when we analyze race performance.

```{r age-qq}
pts <- qqplot(men_df_agecat$age[men_df_agecat$year == 1999],
              men_df_agecat$age[men_df_agecat$year == 2012],
              plot.it = FALSE) %>% as_data_frame()
pts %>% 
  ggplot(aes(x, y)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0) +
  labs(x = 'Age in 1999', y = 'Age in 2012')
```

In the previous chapter, we saw how the average performance was flat for runners in their 30s and rose slightly in the 40s and more sharply in the 50s and 60s. We make separate smooth curves of time versus age for the 1999 and 2012 runners and plot them together as follows:

```{r loess-twoyears, fig.cap="Loess Curves Fit to Performance for 1999 and 2012 Male Runners. This loess fit of run time to age for 2012 male runners sits above the fit for 1999 male runners. The gap between these curves is about 5 minutes for most years. The exception is in the late 40s to early 60s where the curves are within 2–3 minutes of each other. Both curves have a similar shape."}
p <- men_df_agecat %>% 
  filter(year %in% c(1999, 2012)) %>% 
  ggplot(aes(age, time, color = factor(year))) +
  geom_smooth(method = 'loess', se = FALSE, fullrange = TRUE) +
  scale_color_few(name = 'Year') +
  xlim(c(15, 80)) +
  labs(x = 'Age', y = 'Time (minutes)')
p
```

We see in Figure \@ref(fig:loess-twoyears) that the two curves are similar in shape but the curve for 2012 is higher than the 1999 curve. There appears to be a consistent difference between these two groups of runners. Figure \@ref(fig:loess-difference) shows the difference in predicted run times for these two curves. This difference narrows to 2 minutes for men in their 50s and gradually widens for men in their 60s, 70s, and 80s from 2.5 to 8.5 minutes. We leave it as an exercise to compare the run time age relationship for all 14 years of data.

```{r loess-difference, fig.cap="Difference between Loess Curves. This line plot shows the difference between the predicted run time for 2012 and 1999 male runners."}
lo_pr_99 <- predict(loess(time ~ age, 
                          data = men_df_agecat, 
                          subset = men_df_agecat$year == 1999),
                    data_frame(age = age20to80))
lo_pr_12 <- predict(loess(time ~ age, 
                          data = men_df_agecat, 
                          subset = men_df_agecat$year == 2012),
                    data_frame(age = age20to80))
data_frame(age = age20to80, diff = lo_pr_12 - lo_pr_99) %>% 
  ggplot(aes(age, diff)) +
  geom_line() +
  labs(x = 'Age', y = 'Difference in Fitted Curves (minutes)')
```


We mention one last idea for comparing these two distributions of runners, and we leave it to the exercises to carry out this comparison. In track, there is a performance standard called age grading that measures an individual’s performance based on his or her age. It normalizes the individual’s run time by the world record for that distance for that age group. Since the fastest runners in the Cherry Blossom road race perform close to the world record, we might use the fastest runner in each age category to normalize the times. To minimize the year-to-year fluctuations, we can smooth the fastest times and use these smoothed times to normalize each runner’s time. When we do this, we find the age graded performances roughly follow the Normal distribution. However, the 1999 runners tend to be better than their 2012 counterparts as evidenced by the peak at 1.4 rather than 1.5 and a smaller IQR.

The run time distribution appears to have changed over the years, and this points out
the main issue with cross-sectional studies. However, there is an advantage to having 14
years’ worth of race results. It is possible that some runners have participated in the race over several years and we can study how each runner's performance changes as he or she grows older. In order to do this, we need to connect runners across the years.